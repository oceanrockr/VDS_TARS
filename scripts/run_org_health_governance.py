#!/usr/bin/env python3
"""
scripts/run_org_health_governance.py

Organization-Level Health Governance Script for T.A.R.S. Release Pipeline.

This script orchestrates org-level health aggregation:
- Collects per-repo health dashboards, alerts, and trends
- Evaluates SLO/SLA policies across repositories
- Computes org-wide risk metrics
- Generates org health report with recommendations

Integrates with the per-repo pipeline (prepare_release_artifacts.py):
- Consumes artifacts generated by Tasks 8-10
- Can be run after per-repo pipelines complete
- Supports scheduled org-wide health monitoring

Exit Codes (90-99):
    90: Success, no SLO violations
    91: SLO violations detected
    92: Org risk >= HIGH tier threshold
    93: No repos discovered / loaded
    94: Config error
    95: Data aggregation error
    99: General org-health error

Version: 1.0.0
Phase: 14.8 Task 1
"""

import argparse
import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

# ============================================================================
# CONFIGURATION
# ============================================================================

SCRIPT_DIR = Path(__file__).parent.resolve()
PROJECT_ROOT = SCRIPT_DIR.parent

# Default paths
DEFAULT_ORG_HEALTH_DIR = PROJECT_ROOT / "org-health"
DEFAULT_OUTPUT_DIR = PROJECT_ROOT / "release" / "org-health"
DEFAULT_CONFIG_FILE = PROJECT_ROOT / "org-health-config.yaml"

# ============================================================================
# LOGGING SETUP
# ============================================================================

logger = logging.getLogger(__name__)


def setup_logging(verbose: bool = False) -> None:
    """Configure logging based on verbosity level."""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[logging.StreamHandler(sys.stdout)]
    )


# ============================================================================
# ARGUMENT PARSER
# ============================================================================

def create_parser() -> argparse.ArgumentParser:
    """Create argument parser for the script."""
    parser = argparse.ArgumentParser(
        prog="run_org_health_governance",
        description="Organization-Level Health Governance for T.A.R.S. Release Pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exit Codes:
  90  Success, no SLO violations
  91  SLO violations detected
  92  Org risk >= HIGH tier threshold
  93  No repos discovered / loaded
  94  Config error
  95  Data aggregation error
  99  General org-health error

Directory Structure Expected:
  org-health/
    repo-a/
      dashboard/health-dashboard.json
      alerts/alerts.json
      trends/trend-report.json
    repo-b/
      ...

Examples:
  # Basic org health analysis
  python scripts/run_org_health_governance.py --root-dir ./org-health

  # With custom SLO config
  python scripts/run_org_health_governance.py --root-dir ./org-health --config ./org-health-config.yaml

  # Full output with JSON report
  python scripts/run_org_health_governance.py --root-dir ./org-health --output ./org-report.json --json

  # CI/CD mode (fail on violations)
  python scripts/run_org_health_governance.py --root-dir ./org-health --fail-on-slo-violation --fail-on-critical-risk
"""
    )

    # Input paths
    parser.add_argument(
        "--root-dir",
        type=Path,
        default=DEFAULT_ORG_HEALTH_DIR,
        help=f"Root directory containing per-repo health artifacts (default: {DEFAULT_ORG_HEALTH_DIR})"
    )

    parser.add_argument(
        "--config",
        type=Path,
        default=None,
        help="Path to YAML or JSON configuration file with SLO policies"
    )

    # Output configuration
    parser.add_argument(
        "--output",
        type=Path,
        default=None,
        help="Output path for org health report JSON"
    )

    parser.add_argument(
        "--output-dir",
        type=Path,
        default=DEFAULT_OUTPUT_DIR,
        help=f"Output directory for reports (default: {DEFAULT_OUTPUT_DIR})"
    )

    # Repository filtering
    parser.add_argument(
        "--repos",
        type=str,
        default=None,
        help="Comma-separated list of repo IDs to analyze (default: all discovered)"
    )

    parser.add_argument(
        "--exclude-repos",
        type=str,
        default=None,
        help="Comma-separated list of repo IDs to exclude from analysis"
    )

    # Artifact configuration
    parser.add_argument(
        "--dashboard-subdir",
        type=str,
        default="dashboard",
        help="Subdirectory name for dashboard artifacts (default: dashboard)"
    )

    parser.add_argument(
        "--alerts-subdir",
        type=str,
        default="alerts",
        help="Subdirectory name for alert artifacts (default: alerts)"
    )

    parser.add_argument(
        "--trends-subdir",
        type=str,
        default="trends",
        help="Subdirectory name for trend artifacts (default: trends)"
    )

    # SLO configuration
    parser.add_argument(
        "--use-default-slos",
        action="store_true",
        help="Use default SLO policies if no config provided"
    )

    parser.add_argument(
        "--add-slo",
        action="append",
        dest="extra_slos",
        metavar="SLO_JSON",
        help="Add an SLO policy as JSON (can be specified multiple times)"
    )

    # Behavior flags
    parser.add_argument(
        "--fail-on-slo-violation",
        action="store_true",
        help="Exit with code 91 if any SLO is violated"
    )

    parser.add_argument(
        "--fail-on-critical-risk",
        action="store_true",
        help="Exit with code 92 if org risk is HIGH or CRITICAL"
    )

    # Output options
    parser.add_argument(
        "--summary-only",
        action="store_true",
        help="Only print a quick summary (no detailed output)"
    )

    parser.add_argument(
        "--json",
        action="store_true",
        help="Output results as JSON to stdout"
    )

    parser.add_argument(
        "--quiet", "-q",
        action="store_true",
        help="Suppress non-essential output"
    )

    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="Enable verbose output"
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Discover repos and show what would be analyzed without running analysis"
    )

    return parser


# ============================================================================
# MAIN LOGIC
# ============================================================================

def print_header(title: str) -> None:
    """Print a formatted header."""
    print("\n" + "=" * 80)
    print(title)
    print("=" * 80)


def print_section(title: str) -> None:
    """Print a section header."""
    print("\n" + "-" * 40)
    print(title)
    print("-" * 40)


def format_slo_status(satisfied: bool) -> str:
    """Format SLO status for display."""
    return "[OK]" if satisfied else "[VIOLATED]"


def format_health_status(status: str) -> str:
    """Format health status for display."""
    icons = {
        "green": "[G]",
        "yellow": "[Y]",
        "red": "[R]",
        "unknown": "[?]"
    }
    return icons.get(status.lower(), "[?]")


def format_risk_tier(tier: str) -> str:
    """Format risk tier for display."""
    icons = {
        "low": "L",
        "medium": "M",
        "high": "H",
        "critical": "C"
    }
    return icons.get(tier.lower(), "?")


def print_org_health_summary(report: Dict[str, Any]) -> None:
    """Print a formatted summary of the org health report."""
    print_header("ORGANIZATION HEALTH SUMMARY")

    # Org-level status
    status = report.get("org_health_status", "unknown")
    score = report.get("org_health_score", 0)
    risk = report.get("org_risk_tier", "unknown")

    status_display = format_health_status(status)
    print(f"\n{status_display} Overall Health: {status.upper()}")
    print(f"    Score: {score:.1f}/100")
    print(f"    Risk Tier: {risk.upper()}")

    # Repository counts
    metrics = report.get("metrics", {})
    print_section("REPOSITORIES")
    print(f"  Total: {metrics.get('total_repos', 0)}")
    print(f"  GREEN: {metrics.get('repos_green', 0)} | YELLOW: {metrics.get('repos_yellow', 0)} | RED: {metrics.get('repos_red', 0)}")

    # Trend distribution
    improving = metrics.get("repos_improving", 0)
    stable = metrics.get("repos_stable", 0)
    declining = metrics.get("repos_declining", 0)
    if improving or stable or declining:
        print(f"  Improving: {improving} | Stable: {stable} | Declining: {declining}")

    # Risk distribution
    print_section("RISK TIERS")
    print(f"  LOW: {metrics.get('repos_low_risk', 0)}")
    print(f"  MEDIUM: {metrics.get('repos_medium_risk', 0)}")
    print(f"  HIGH: {metrics.get('repos_high_risk', 0)}")
    print(f"  CRITICAL: {metrics.get('repos_critical_risk', 0)}")

    # SLO status
    print_section("SLO STATUS")
    total_slos = report.get("total_slos", 0)
    satisfied = report.get("slos_satisfied", 0)
    violated = report.get("slos_violated", 0)
    print(f"  Total: {total_slos}")
    print(f"  Satisfied: {satisfied}")
    print(f"  Violated: {violated}")

    if violated > 0:
        print("\n  VIOLATED SLOs:")
        for result in report.get("slo_results", []):
            if not result.get("satisfied"):
                slo_id = result.get("slo_id", "unknown")
                desc = result.get("slo_description", "")
                current = result.get("current_value", 0)
                target = result.get("target_value", 0)
                op = result.get("operator", ">=")
                violators = result.get("violating_repos", [])

                print(f"    - [{slo_id}] {desc}")
                print(f"      Current: {current:.2f} | Target: {op} {target}")
                if violators:
                    display_violators = violators[:5]
                    print(f"      Violating repos: {', '.join(display_violators)}")
                    if len(violators) > 5:
                        print(f"        ... and {len(violators) - 5} more")

    # Top risk repos
    top_risk = report.get("top_risk_repos", [])
    if top_risk:
        print_section("TOP RISK REPOSITORIES")
        for i, repo in enumerate(top_risk[:5], 1):
            name = repo.get("repo_name", repo.get("repo_id", "unknown"))
            tier = repo.get("risk_tier", "unknown")
            score = repo.get("repository_score", 0)
            trend = repo.get("trend_direction", "unknown")
            reasons = repo.get("reason_codes", [])

            print(f"  {i}. {name} ({tier.upper()})")
            print(f"     Score: {score:.1f} | Trend: {trend}")
            if reasons:
                print(f"     Reasons: {', '.join(reasons[:3])}")

    # Recommendations
    recommendations = report.get("recommendations", [])
    if recommendations:
        print_section("RECOMMENDATIONS")
        for rec in recommendations[:3]:
            priority = rec.get("priority", "medium")
            title = rec.get("title", "")
            message = rec.get("message", "")
            affected = rec.get("affected_repos", [])

            priority_icons = {
                "critical": "[!!!]",
                "high": "[!!]",
                "medium": "[!]",
                "low": "[.]"
            }
            icon = priority_icons.get(priority, "[?]")

            print(f"  {icon} {title}")
            print(f"      {message}")
            if affected:
                display_affected = affected[:3]
                print(f"      Affected: {', '.join(display_affected)}")
                if len(affected) > 3:
                    print(f"        ... and {len(affected) - 3} more")

    # Metadata
    print("\n" + "=" * 80)
    print(f"Generated: {report.get('generated_at', 'unknown')}")
    print(f"Repos: Discovered={report.get('repos_discovered', 0)} | Loaded={report.get('repos_loaded', 0)} | Failed={report.get('repos_failed', 0)}")
    print(f"Analysis Duration: {report.get('analysis_duration_ms', 0):.1f}ms")
    print("=" * 80)


def main() -> int:
    """Main entry point."""
    parser = create_parser()
    args = parser.parse_args()

    # Setup logging
    setup_logging(args.verbose)

    # Import org health module
    try:
        sys.path.insert(0, str(PROJECT_ROOT))
        from analytics.org_health_aggregator import (
            OrgHealthConfig,
            OrgHealthEngine,
            SloPolicy,
            load_slo_config,
            create_default_slo_policies,
            EXIT_ORG_SUCCESS,
            EXIT_SLO_VIOLATIONS,
            EXIT_HIGH_ORG_RISK,
            EXIT_NO_REPOS_DISCOVERED,
            EXIT_CONFIG_ERROR,
            EXIT_AGGREGATION_ERROR,
            EXIT_GENERAL_ORG_ERROR,
        )
    except ImportError as e:
        logger.error(f"Failed to import org health aggregator module: {e}")
        logger.error("Ensure analytics.org_health_aggregator module is available")
        return 99

    try:
        if not args.quiet:
            print_header("T.A.R.S. ORGANIZATION HEALTH GOVERNANCE")
            print(f"\nRoot Directory: {args.root_dir}")
            print(f"Config: {args.config or '(default SLOs)' if args.use_default_slos else '(none)'}")

        # Check root directory
        root_dir = args.root_dir
        if not root_dir.exists():
            logger.error(f"Root directory does not exist: {root_dir}")
            return EXIT_NO_REPOS_DISCOVERED

        # Load SLO policies
        slo_policies = []

        if args.config and args.config.exists():
            try:
                slo_policies = load_slo_config(args.config)
                logger.info(f"Loaded {len(slo_policies)} SLO policies from {args.config}")
            except Exception as e:
                logger.error(f"Failed to load config: {e}")
                return EXIT_CONFIG_ERROR
        elif args.use_default_slos:
            slo_policies = create_default_slo_policies()
            logger.info(f"Using {len(slo_policies)} default SLO policies")

        # Add extra SLOs from command line
        if args.extra_slos:
            for slo_json in args.extra_slos:
                try:
                    slo_data = json.loads(slo_json)
                    slo_policies.append(SloPolicy.from_dict(slo_data))
                except Exception as e:
                    logger.warning(f"Failed to parse SLO from command line: {e}")

        # Parse repo filters
        repo_filter = None
        if args.repos:
            repo_filter = [r.strip() for r in args.repos.split(',')]

        # Determine output path
        output_path = args.output
        if not output_path:
            args.output_dir.mkdir(parents=True, exist_ok=True)
            output_path = args.output_dir / f"org-health-report-{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.json"

        # Build configuration
        config = OrgHealthConfig(
            root_dir=root_dir,
            dashboard_subdir=args.dashboard_subdir,
            alerts_subdir=args.alerts_subdir,
            trends_subdir=args.trends_subdir,
            output_path=output_path,
            slo_policies=slo_policies,
            fail_on_slo_violation=args.fail_on_slo_violation,
            fail_on_critical_org_risk=args.fail_on_critical_risk,
            verbose=args.verbose,
            repo_filter=repo_filter
        )

        # Dry run mode
        if args.dry_run:
            logger.info("\nDRY RUN MODE - Discovering repos without analysis")
            from analytics.org_health_aggregator import OrgHealthAggregator
            aggregator = OrgHealthAggregator(config)
            repos = aggregator.discover_repositories()

            print(f"\nDiscovered {len(repos)} repositories:")
            for repo_id in repos:
                has_dashboard = aggregator._check_artifact_exists(root_dir / repo_id, "dashboard")
                has_alerts = aggregator._check_artifact_exists(root_dir / repo_id, "alerts")
                has_trends = aggregator._check_artifact_exists(root_dir / repo_id, "trends")
                artifacts = []
                if has_dashboard:
                    artifacts.append("dashboard")
                if has_alerts:
                    artifacts.append("alerts")
                if has_trends:
                    artifacts.append("trends")
                print(f"  - {repo_id}: {', '.join(artifacts) or 'no artifacts'}")

            return EXIT_ORG_SUCCESS

        # Run analysis
        engine = OrgHealthEngine(config)
        report, exit_code = engine.run()

        # Output results
        if args.json:
            print(json.dumps(report.to_dict(), indent=2, default=str))
        elif not args.quiet:
            print_org_health_summary(report.to_dict())

        if not args.quiet:
            print(f"\nReport written to: {output_path}")
            print(f"Exit code: {exit_code}")

        return exit_code

    except KeyboardInterrupt:
        print("\nAnalysis cancelled by user")
        return EXIT_GENERAL_ORG_ERROR
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return EXIT_GENERAL_ORG_ERROR


if __name__ == "__main__":
    sys.exit(main())
