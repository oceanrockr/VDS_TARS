# T.A.R.S. Cognitive Analytics Core - Insight Engine

**Version**: 0.8.0-alpha
**Phase**: 10 - Cognitive Federation & Adaptive Policy Learning

## Overview

The Cognitive Analytics Core is the intelligence layer of T.A.R.S. that continuously learns from operational data to generate adaptive insights for policy optimization, consensus tuning, and ethical governance improvements.

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                  Cognitive Analytics Core                    │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  ┌──────────────┐     ┌──────────────┐    ┌──────────────┐ │
│  │   Stream     │────▶│  Analyzer    │───▶│ Recommender  │ │
│  │  Processor   │     │  Engine      │    │   Service    │ │
│  └──────────────┘     └──────────────┘    └──────────────┘ │
│         │                     │                    │         │
│         ▼                     ▼                    ▼         │
│  ┌──────────────────────────────────────────────────────┐  │
│  │           PostgreSQL (cognitive_insights)             │  │
│  └──────────────────────────────────────────────────────┘  │
│                                                               │
│  Data Sources:                                               │
│  • policy_audit logs                                         │
│  • consensus_metrics                                         │
│  • anomaly_logs                                              │
│  • ethical_policy_audits                                     │
└─────────────────────────────────────────────────────────────┘
```

## Components

### 1. Stream Processor (`stream_processor.py`)
- **Purpose**: Continuously consumes audit logs, metrics, and events
- **Analysis Window**: Configurable (default: 60 minutes)
- **Refresh Interval**: Configurable (default: 60 seconds)
- **Features**:
  - Policy metrics aggregation
  - Consensus performance analysis
  - Ethical fairness tracking
  - Anomaly correlation detection

### 2. Analyzer Engine (embedded in `stream_processor.py`)
- **Policy Optimization**: Identifies over/under-constrained policies
- **Consensus Tuning**: Detects latency issues and quorum failures
- **Ethical Threshold Adjustment**: Monitors fairness scores and bias
- **Correlation Analysis**: Links policies to MTTR and effectiveness

### 3. Recommender Service (`recommender.py`)
- **REST API**: Serves insights via `/api/v1/insights/recommendations`
- **Filtering**: By type, priority, confidence threshold
- **State Management**: Tracks applied/rejected insights
- **Scoring**: Composite score (70% confidence + 30% impact)

### 4. FastAPI Server (`main.py`)
- **Port**: 8090
- **Endpoints**:
  - `POST /api/v1/insights/recommendations` - Get recommendations
  - `GET /api/v1/insights/{id}` - Get specific insight
  - `POST /api/v1/insights/{id}/status` - Update insight status
  - `GET /api/v1/state` - Get cognitive system state
  - `POST /api/v1/insights/trigger` - Manually trigger analysis
  - `GET /metrics` - Prometheus metrics

## Insight Types

| Type | Description | Example |
|------|-------------|---------|
| `policy_optimization` | Policy constraint adjustments | "Reduce scaling cooldown from 60s to 30s" |
| `consensus_tuning` | Consensus timeout/quorum tuning | "Reduce Raft timeout by 20% to improve latency" |
| `ethical_threshold` | Fairness threshold adjustments | "Lower fairness threshold to 0.70 for better balance" |
| `anomaly_correlation` | Link policies to anomaly outcomes | "Policy X reduces MTTR by 25%" |
| `resource_efficiency` | Resource usage optimization | "Adjust replicas based on load patterns" |

## Insight Priorities

- **CRITICAL**: Immediate action required (e.g., high quorum failures)
- **HIGH**: Significant impact (e.g., high violation rate)
- **MEDIUM**: Moderate improvement opportunity
- **LOW**: Minor optimization

## API Examples

### Get Recommendations
```bash
curl -X POST http://localhost:8090/api/v1/insights/recommendations \
  -H "Content-Type: application/json" \
  -d '{
    "insight_types": ["policy_optimization", "consensus_tuning"],
    "min_confidence": 0.8,
    "priority": "high",
    "limit": 10
  }'
```

### Update Insight Status
```bash
curl -X POST http://localhost:8090/api/v1/insights/insight-001/status?status=applied
```

### Get Cognitive State
```bash
curl http://localhost:8090/api/v1/state
```

### Trigger Manual Analysis
```bash
curl -X POST http://localhost:8090/api/v1/insights/trigger
```

## Metrics

| Metric | Type | Description |
|--------|------|-------------|
| `tars_cognitive_recommendation_score` | Gauge | Recommendation score per insight |
| `tars_cognitive_insights_generated_total` | Counter | Total insights generated by type/priority |
| `tars_cognitive_insights_applied_total` | Counter | Total insights successfully applied |
| `tars_cognitive_insight_processing_seconds` | Histogram | Time to generate insights |
| `tars_cognitive_recommendation_requests_total` | Counter | API requests for recommendations |

## Configuration

Environment variables (`.env` or Kubernetes ConfigMap):

```bash
# Database
POSTGRES_URL=postgresql://tars:tars@postgres:5432/tars

# Analysis
INSIGHT_REFRESH_INTERVAL=60  # seconds
ANALYSIS_WINDOW_MINUTES=60   # minutes

# Thresholds
HIGH_VIOLATION_RATE_THRESHOLD=0.3
LOW_VIOLATION_RATE_THRESHOLD=0.05
HIGH_CONSENSUS_LATENCY_THRESHOLD=400.0  # ms
ETHICAL_FAIRNESS_THRESHOLD=0.75

# Sample sizes
MIN_SAMPLE_SIZE_POLICY=50
MIN_SAMPLE_SIZE_ETHICAL=30
MIN_SAMPLE_SIZE_CONSENSUS=20

# Feature flags
COGNITION_ENABLED=true
ADAPTIVE_POLICY_LEARNING=true
META_CONSENSUS_OPTIMIZER=true
ETHICAL_TRAINER_ENABLED=true
```

## Database Schema

```sql
CREATE TABLE cognitive_insights (
    id VARCHAR(255) PRIMARY KEY,
    type VARCHAR(50) NOT NULL,
    priority VARCHAR(20) NOT NULL,
    title TEXT NOT NULL,
    description TEXT NOT NULL,
    recommendation JSONB NOT NULL,
    confidence_score FLOAT NOT NULL,
    evidence JSONB,
    impact_estimate JSONB,
    status VARCHAR(20) DEFAULT 'pending',
    timestamp TIMESTAMP DEFAULT NOW(),
    expires_at TIMESTAMP
);

CREATE INDEX idx_insights_status ON cognitive_insights(status);
CREATE INDEX idx_insights_type ON cognitive_insights(type);
CREATE INDEX idx_insights_timestamp ON cognitive_insights(timestamp DESC);
CREATE INDEX idx_insights_confidence ON cognitive_insights(confidence_score DESC);
```

## Running Locally

```bash
# Install dependencies
cd cognition/insight-engine
pip install -r requirements.txt

# Set environment variables
export POSTGRES_URL="postgresql://tars:tars@localhost:5432/tars"
export INSIGHT_REFRESH_INTERVAL=60

# Run server
python main.py
```

## Docker Deployment

```bash
docker build -t tars-cognitive-insight-engine:0.8.0 .
docker run -p 8090:8090 \
  -e POSTGRES_URL="postgresql://tars:tars@postgres:5432/tars" \
  -e INSIGHT_REFRESH_INTERVAL=60 \
  tars-cognitive-insight-engine:0.8.0
```

## Integration with Policy Learner

The Insight Engine generates recommendations that are consumed by the Adaptive Policy Learner:

1. **Insight Engine** generates `AdaptiveInsight` with recommendations
2. **Policy Learner** polls `/api/v1/insights/recommendations`
3. **Policy Learner** validates recommendations via dry-run
4. **Policy Learner** submits validated changes to Federation Hub for vote
5. **Insight Engine** updates status to `applied` or `rejected` based on outcome

## Testing

```bash
# Run unit tests
pytest tests/ -v

# Run integration test
python -m pytest tests/test_integration.py -v

# Manual testing
curl http://localhost:8090/health
curl -X POST http://localhost:8090/api/v1/insights/trigger
```

## Performance Targets

| Metric | Target | Notes |
|--------|--------|-------|
| Insight Latency | ≤ 5s | End-to-end generation time |
| API Response Time | ≤ 100ms | P95 for recommendation queries |
| Analysis Accuracy | ≥ 90% | vs. manual baseline |
| Database Load | ≤ 100 QPS | Steady-state queries per second |
| Memory Usage | ≤ 1Gi | Pod resource limit |

## Troubleshooting

### High Latency
- Check database query performance (`EXPLAIN ANALYZE`)
- Verify indexes exist on `cognitive_insights` table
- Reduce `ANALYSIS_WINDOW_MINUTES` if processing too much data

### No Insights Generated
- Check `policy_audit` table has recent entries
- Verify thresholds in config (may be too strict)
- Manually trigger: `POST /api/v1/insights/trigger`

### Database Connection Errors
- Verify `POSTGRES_URL` is correct
- Check PostgreSQL is running and accessible
- Check network policies in Kubernetes

## Future Enhancements

- **Online Learning**: Update ML models in real-time
- **Explainability**: Add LIME/SHAP for recommendation explanations
- **A/B Testing**: Test policy changes with traffic splitting
- **Federated Insights**: Share insights across clusters
- **Predictive Analysis**: Forecast policy violations before they occur

## References

- [Phase 10 Implementation Report](../../PHASE10_IMPLEMENTATION_REPORT.md)
- [Policy Learner](../../governance/policy-learner/README.md)
- [Meta-Consensus Optimizer](../../federation/meta-controller/README.md)
